spring:
  application:
    name: pulse-anomaly-service
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      properties:
        enable.idempotence: true
        acks: all
    properties:
      schema.registry.url: ${SCHEMA_REGISTRY_URL:http://localhost:8081}
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
  datasource:
    url: ${DB_URL:jdbc:postgresql://localhost:5432/pulse}
    username: ${DB_USER:pulse}
    password: ${DB_PASSWORD:pulse}
  jpa:
    hibernate:
      ddl-auto: none
    properties:
      hibernate.jdbc.time_zone: UTC

pulse:
  trends:
    zset-key: trends:global
    last-counts-hash: trends:last_counts
    activity-zset-key: trends:lastSeen
  anomalies:
    topic: ${ANOMALY_TOPIC:detected_anomalies}
    z-threshold: ${Z_THRESHOLD:2.5}
    history-window: ${HISTORY_WINDOW:360}
    min-z-step: ${ANOMALY_MIN_Z_STEP:1.0}
    last-z-ttl-seconds: ${ANOMALY_LAST_Z_TTL_SECONDS:86400}
    baseline-volume-min: ${ANOMALY_BASELINE_VOLUME_MIN:10}
    history-ttl-seconds: ${ANOMALY_HISTORY_TTL_SECONDS:172800}
    min-samples: ${ANOMALY_MIN_SAMPLES:10}
    # time-based candidate scan horizon/retention (millis)
    activity-horizon-ms: ${PULSE_ACTIVITY_HORIZON_MS:60000}
    activity-retention-ms: ${PULSE_ACTIVITY_RETENTION_MS:86400000}
  scheduler:
    interval-ms: ${PULSE_SCHEDULER_INTERVAL_MS:5000}
    lock-key: anomaly:lock
    lock-ttl-ms: ${SCHEDULE_LOCK_TTL_MS:20000}

logging:
  level:
    org.springframework: debug
    org.springframework.kafka: warn
    com.pulse.anomaly: debug

management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  endpoint:
    health:
      probes:
        enabled: true
  metrics:
    tags:
      application: ${spring.application.name}
  prometheus:
    metrics:
      export:
        enabled: true